{
  "id": "417",
  "link": "https://www.exploit-db.com/ghdb/417",
  "category": "Files Containing Juicy Info",
  "short_description": "(inurl:\"robot.txt\" | inurl:\"robots.txt\" ) intext:disallow filetype:txt",
  "textual_description": "Webmasters wanting to exclude search engine robots from certain parts of their site often choose the use of a robot.txt file on the root of the server. This file basicly tells the bot which directories are supposed to be off-limits.An attacker can easily obtain that information by very simply opening that plain text file in his browser. Webmasters should *never* rely on this for real security issues. Google helps the attacker by allowing a search for the \"disallow\" keyword.",
  "query": "(inurl:\"robot.txt\" | inurl:\"robots.txt\" ) intext:disallow filetype:txt",
  "querystring": "https://www.google.com/search?num=100&q=%28inurl%3A%22robot.txt%22+%7C+inurl%3A%22robots.txt%22+%29+intext%3Adisallow+filetype%3Atxt",
  "date": "2004-08-09",
  "author": "anonymous"
}
